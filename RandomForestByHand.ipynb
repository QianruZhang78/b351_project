{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f8d5ee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2002-02-06    0.0\n",
      "2002-02-07    0.0\n",
      "2002-02-08    0.0\n",
      "2002-02-11    0.0\n",
      "2002-02-12    0.0\n",
      "Name: signal, dtype: float64\n",
      "              Vol-5d    Return\n",
      "Date                          \n",
      "2002-02-06  0.034578 -0.030647\n",
      "2002-02-07  0.029778 -0.014998\n",
      "2002-02-08  0.026198 -0.011112\n",
      "2002-02-11  0.030424  0.039534\n",
      "2002-02-12  0.029153 -0.010808\n",
      "Date\n",
      "2004-10-06    0.0\n",
      "2004-10-07    0.0\n",
      "2004-10-08    0.0\n",
      "2004-10-11    0.0\n",
      "2004-10-12    0.0\n",
      "Name: signal, dtype: float64\n",
      "              Vol-5d    Return\n",
      "Date                          \n",
      "2004-10-06  0.018091 -0.009323\n",
      "2004-10-07  0.014794  0.012912\n",
      "2004-10-08  0.015565 -0.008066\n",
      "2004-10-11  0.015753 -0.017934\n",
      "2004-10-12  0.017356  0.015821\n",
      "Date\n",
      "2002-07-11    0.0\n",
      "2002-07-12    0.0\n",
      "2002-07-15    0.0\n",
      "2002-07-16    0.0\n",
      "2002-07-17    0.0\n",
      "Name: signal, dtype: float64\n",
      "              Vol-5d    Return\n",
      "Date                          \n",
      "2002-07-11  0.069877  0.090854\n",
      "2002-07-12  0.064332 -0.048397\n",
      "2002-07-15  0.082005 -0.053814\n",
      "2002-07-16  0.021379 -0.014374\n",
      "2002-07-17  0.019731 -0.032974\n",
      "Date\n",
      "2002-02-06    0.0\n",
      "2002-02-07    0.0\n",
      "2002-02-08    0.0\n",
      "2002-02-11    0.0\n",
      "2002-02-12    0.0\n",
      "Name: signal, dtype: float64\n",
      "              Vol-5d    Return\n",
      "Date                          \n",
      "2002-02-06  0.037002 -0.020870\n",
      "2002-02-07  0.043185 -0.001776\n",
      "2002-02-08  0.081509  0.113879\n",
      "2002-02-11  0.057940  0.062300\n",
      "2002-02-12  0.072934 -0.030075\n",
      "Date\n",
      "2002-02-06    0.0\n",
      "2002-02-07    0.0\n",
      "2002-02-08    0.0\n",
      "2002-02-11    0.0\n",
      "2002-02-12    0.0\n",
      "Name: signal, dtype: float64\n",
      "              Vol-5d    Return\n",
      "Date                          \n",
      "2002-02-06  0.037002 -0.020870\n",
      "2002-02-07  0.043185 -0.001776\n",
      "2002-02-08  0.081509  0.113879\n",
      "2002-02-11  0.057940  0.062300\n",
      "2002-02-12  0.072934 -0.030075\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from pandas import read_csv\n",
    "\n",
    "aapl = pd.read_csv(r'C:\\Users\\Zz\\Desktop\\aapl.csv', header = 0, index_col = 0)\n",
    "X = aapl[['Vol-5d', 'Return']]\n",
    "Y = aapl['signal']\n",
    "print(Y.head())\n",
    "print(X.head())\n",
    "Y= Y.apply(np.int64)\n",
    "X_train = X[:3000]\n",
    "y_train = Y[:3000].values\n",
    "X_test = X[3000:]\n",
    "y_test = Y[3000:].values\n",
    "\n",
    "googl = pd.read_csv(r'C:\\Users\\Zz\\Desktop\\googl.csv', header = 0, index_col = 0)\n",
    "X1 = googl[['Vol-5d', 'Return']]\n",
    "Y1 = googl['signal']\n",
    "print(Y1.head())\n",
    "print(X1.head())\n",
    "Y1= Y1.apply(np.int64)\n",
    "X1_train = X1[:3000]\n",
    "y1_train = Y1[:3000].values\n",
    "X1_test = X1[3000:]\n",
    "y1_test = Y1[3000:].values\n",
    "\n",
    "nflx = pd.read_csv(r'C:\\Users\\Zz\\Desktop\\nflx.csv', header = 0, index_col = 0)\n",
    "X2 = nflx[['Vol-5d', 'Return']]\n",
    "Y2 = nflx['signal']\n",
    "print(Y2.head())\n",
    "print(X2.head())\n",
    "Y2= Y2.apply(np.int64)\n",
    "X2_train = X2[:3000]\n",
    "y2_train = Y2[:3000].values\n",
    "X2_test = X2[3000:]\n",
    "y2_test = Y2[3000:].values\n",
    "\n",
    "amzn = pd.read_csv(r'C:\\Users\\Zz\\Desktop\\amzn.csv', header = 0, index_col = 0)\n",
    "X3 = amzn[['Vol-5d', 'Return']]\n",
    "Y3 = amzn['signal']\n",
    "print(Y3.head())\n",
    "print(X3.head())\n",
    "Y3= Y3.apply(np.int64)\n",
    "X3_train = X3[:3000]\n",
    "y3_train = Y3[:3000].values\n",
    "X3_test = X3[3000:]\n",
    "y3_test = Y3[3000:].values\n",
    "\n",
    "fb = pd.read_csv(r'C:\\Users\\Zz\\Desktop\\fb.csv', header = 0, index_col = 0)\n",
    "X4 = amzn[['Vol-5d', 'Return']]\n",
    "Y4 = amzn['signal']\n",
    "print(Y4.head())\n",
    "print(X4.head())\n",
    "Y4= Y4.apply(np.int64)\n",
    "X4_train = X4[:3000]\n",
    "y4_train = Y4[:3000].values\n",
    "X4_test = X4[3000:]\n",
    "y4_test = Y4[3000:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "845d0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    if p == 0 or p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return - (p * np.log2(p) + (1 - p) * math.log2(1-p))\n",
    "\n",
    "def information_gain(l, r):\n",
    "    parent = l + r\n",
    "    if len(parent) > 0:\n",
    "        parent_p = parent.count(1) / len(parent)\n",
    "    else:\n",
    "        parent_p = 0\n",
    "    if len(l) > 0:\n",
    "        l_p = l.count(1) / len(l)\n",
    "    else:\n",
    "        l_p = 0\n",
    "    if len(r) > 0:\n",
    "        r_p = r.count(1) / len(r)\n",
    "    else:\n",
    "        r_p = 0    \n",
    "    \n",
    "    parent_informationGain = entropy(parent_p)\n",
    "    l_informationGain = entropy(l_p)\n",
    "    r_informationGain = entropy(r_p)\n",
    "    return parent_informationGain - len(l) / len(parent) * l_informationGain - len(r) / len(parent) * r_informationGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9aaf515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bootstrap(X_train, y_train):\n",
    "    bootstrap_indices = list(np.random.choice(range(len(X_train)), len(X_train), replace = True))\n",
    "    X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "    return X_bootstrap, y_bootstrap\n",
    "\n",
    "#This code snippet was reffered to program by carbonati(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75eb4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split_point(X_bootstrap, y_bootstrap, max_features):\n",
    "    feature_ls = list()\n",
    "    num_features = len(X_bootstrap[0])\n",
    "\n",
    "    while len(feature_ls) <= max_features:\n",
    "        index = random.sample(range(num_features), 1)\n",
    "        if index not in feature_ls:\n",
    "            feature_ls.extend(index)\n",
    "\n",
    "    best_informationGain = -math.inf\n",
    "    node = None\n",
    "    for index in feature_ls:\n",
    "        for split_point in X_bootstrap[:,index]:\n",
    "            l = {'X_bootstrap': [], 'y_bootstrap': []}\n",
    "            r = {'X_bootstrap': [], 'y_bootstrap': []}      \n",
    "        if type(split_point) in [int, float]:\n",
    "            for i, value in enumerate(X_bootstrap[:,index]):\n",
    "                if value > split_point:\n",
    "                    r['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    r['y_bootstrap'].append(y_bootstrap[i])\n",
    "                else:\n",
    "                    l['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    l['y_bootstrap'].append(y_bootstrap[i])\n",
    "        else:\n",
    "            for i, value in enumerate(X_bootstrap[:,index]):\n",
    "                if value == split_point:\n",
    "                    l['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    l['y_bootstrap'].append(y_bootstrap[i])\n",
    "                else:\n",
    "                    r['X_bootstrap'].append(X_bootstrap[i])\n",
    "                    r['y_bootstrap'].append(y_bootstrap[i])\n",
    "\n",
    "        split_informationGain = information_gain(l['y_bootstrap'], r['y_bootstrap'])\n",
    "        if split_informationGain > best_informationGain:\n",
    "            best_informationGain = split_informationGain\n",
    "            l['X_bootstrap'] = np.array(l['X_bootstrap'])\n",
    "            r['X_bootstrap'] = np.array(r['X_bootstrap'])\n",
    "            node = {'information_gain': split_informationGain,\n",
    "                    'left_child': l,\n",
    "                    'right_child': r,\n",
    "                    'split_point': split_point,\n",
    "                    'index': index}\n",
    "    return node\n",
    "\n",
    "#This code snippet was reffered to program by carbonati(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "72771dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_node(node):\n",
    "    y_bootstrap = node['y_bootstrap']\n",
    "    pred = max(y_bootstrap, key = y_bootstrap.count)\n",
    "    return pred\n",
    "\n",
    "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
    "    l = node['left_child']\n",
    "    r = node['right_child']\n",
    "\n",
    "    del(node['left_child'])\n",
    "    del(node['right_child'])\n",
    "\n",
    "    if len(l['y_bootstrap']) == 0 or len(r['y_bootstrap']) == 0:\n",
    "        empty_child = {'y_bootstrap': l['y_bootstrap'] + r['y_bootstrap']}\n",
    "        node['left_split'] = terminal_node(empty_child)\n",
    "        node['right_split'] = terminal_node(empty_child)\n",
    "        return\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        node['left_split'] = terminal_node(l)\n",
    "        node['right_split'] = terminal_node(r)\n",
    "        return node\n",
    "\n",
    "    if len(l['X_bootstrap']) <= min_samples_split:\n",
    "        node['left_split'] = node['right_split'] = terminal_node(l)\n",
    "    else:\n",
    "        node['left_split'] = find_split_point(l['X_bootstrap'], l['y_bootstrap'], max_features)\n",
    "        split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth + 1)\n",
    "    if len(r['X_bootstrap']) <= min_samples_split:\n",
    "        node['right_split'] = node['left_split'] = terminal_node(r)\n",
    "    else:\n",
    "        node['right_split'] = find_split_point(r['X_bootstrap'], r['y_bootstrap'], max_features)\n",
    "        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)\n",
    "        \n",
    "#This code snippet was reffered to program by carbonati(username)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cca27ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):\n",
    "    root_node = find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
    "    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
    "    return root_node\n",
    "\n",
    "def random_forest(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split):\n",
    "    tree_ls = list()\n",
    "    oob_ls = list()\n",
    "    for i in range(n_estimators):\n",
    "        X_bootstrap, y_bootstrap = draw_bootstrap(X_train, y_train)\n",
    "        tree = build_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
    "        tree_ls.append(tree)\n",
    "    return tree_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f161ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(tree, X_test):\n",
    "    index = tree['index']\n",
    "\n",
    "    if X_test[index] <= tree['split_point']:\n",
    "        if type(tree['left_split']) == dict:\n",
    "            return predict_tree(tree['left_split'], X_test)\n",
    "        else:\n",
    "            value = tree['left_split']\n",
    "            return value\n",
    "    else:\n",
    "        if type(tree['right_split']) == dict:\n",
    "            return predict_tree(tree['right_split'], X_test)\n",
    "        else:\n",
    "            return tree['right_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c0e922dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rf(tree_ls, X_test):\n",
    "    pred_ls = list()\n",
    "    for i in range(len(X_test)):\n",
    "        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
    "        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
    "        pred_ls.append(final_pred)\n",
    "    return np.array(pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a319505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aapl\n",
      "0.5737131434282858\n",
      "googl\n",
      "0.49473684210526314\n",
      "nflx\n",
      "0.5073917634635692\n",
      "amzn\n",
      "0.47276361819090457\n",
      "fb\n",
      "0.5067466266866567\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 1000\n",
    "max_features = 2\n",
    "max_depth = 10\n",
    "min_samples_split = 2\n",
    "\n",
    "model = random_forest(X_train, y_train, n_estimators=1000, max_features = 2, max_depth=10, min_samples_split=2)\n",
    "pred = predict_rf(model, X_test)\n",
    "accuracy = sum(pred == y_test) / len(y_test)\n",
    "print('Aapl')\n",
    "print(accuracy)\n",
    "\n",
    "model1 = random_forest(X1_train, y1_train, n_estimators=1000, max_features = 2, max_depth=10, min_samples_split=2)\n",
    "pred1 = predict_rf(model1, X1_test)\n",
    "accuracy1 = sum(pred1 == y1_test) / len(y1_test)\n",
    "print('googl')\n",
    "print(accuracy1)\n",
    "\n",
    "model2 = random_forest(X2_train, y2_train, n_estimators=1000, max_features = 2, max_depth=10, min_samples_split=2)\n",
    "pred2 = predict_rf(model2, X2_test)\n",
    "accuracy2 = sum(pred2 == y2_test) / len(y2_test)\n",
    "print('nflx')\n",
    "print(accuracy2)\n",
    "\n",
    "model3 = random_forest(X3_train, y3_train, n_estimators=1000, max_features = 2, max_depth=10, min_samples_split=2)\n",
    "pred3 = predict_rf(model3, X3_test)\n",
    "accuracy3 = sum(pred3 == y3_test) / len(y3_test)\n",
    "print('amzn')\n",
    "print(accuracy3)\n",
    "\n",
    "model4 = random_forest(X4_train, y4_train, n_estimators=1000, max_features = 2, max_depth=10, min_samples_split=2)\n",
    "pred4 = predict_rf(model4, X4_test)\n",
    "accuracy4 = sum(pred4 == y4_test) / len(y4_test)\n",
    "print('fb')\n",
    "print(accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3414dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19910e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3aa527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
